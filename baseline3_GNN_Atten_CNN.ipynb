{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import glob\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json',lines=True)\n",
    "test = pd.read_json('test.json',lines=True)\n",
    "sub_sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_dir = None\n",
    "denoise=True\n",
    "if denoise:\n",
    "    train = train[train.signal_to_noise > 1].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pub = test[test[\"seq_length\"] == 107]\n",
    "test_pri = test[test[\"seq_length\"] == 130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3f05a8654f4bdfb61346f87ba7fd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2096.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8747176d6143bb89eb3059b35c421f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=629.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89265aa15d1c477894ffa586f74fdf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3005.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "As = []\n",
    "for id in tqdm(train[\"id\"]):\n",
    "    a = np.load(f\"bpps/{id}.npy\")\n",
    "    As.append(a)\n",
    "As = np.array(As)\n",
    "As_pub = []\n",
    "for id in tqdm(test_pub[\"id\"]):\n",
    "    a = np.load(f\"bpps/{id}.npy\")\n",
    "    As_pub.append(a)\n",
    "As_pub = np.array(As_pub)\n",
    "As_pri = []\n",
    "for id in tqdm(test_pri[\"id\"]):\n",
    "    a = np.load(f\"bpps/{id}.npy\")\n",
    "    As_pri.append(a)\n",
    "As_pri = np.array(As_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>deg_error_Mg_pH10</th>\n",
       "      <th>deg_error_pH10</th>\n",
       "      <th>deg_error_Mg_50C</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>[0.26130000000000003, 0.38420000000000004, 0.1...</td>\n",
       "      <td>[0.2631, 0.28600000000000003, 0.0964, 0.1574, ...</td>\n",
       "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>[0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...</td>\n",
       "      <td>[0.17020000000000002, 0.178, 0.111, 0.091, 0.0...</td>\n",
       "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>id_00ab2d761</td>\n",
       "      <td>GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...</td>\n",
       "      <td>.....(.(((((.(((((((((...........)))))))..(((....</td>\n",
       "      <td>EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...</td>\n",
       "      <td>4.136</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...</td>\n",
       "      <td>[0.2726, 0.2984, 0.21660000000000001, 0.1637, ...</td>\n",
       "      <td>[0.3393, 0.2728, 0.2005, 0.1703, 0.1495, 0.134...</td>\n",
       "      <td>[0.165, 0.20520000000000002, 0.179, 0.1333, 0....</td>\n",
       "      <td>[0.2864, 0.24710000000000001, 0.2222, 0.1903, ...</td>\n",
       "      <td>[0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...</td>\n",
       "      <td>[0.9559000000000001, 1.9442, 1.0114, 0.5105000...</td>\n",
       "      <td>[1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...</td>\n",
       "      <td>[0.22460000000000002, 1.7281, 1.381, 0.6623, 0...</td>\n",
       "      <td>[0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>id_00abef1d7</td>\n",
       "      <td>GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...</td>\n",
       "      <td>.........((((((((......((((((((((((....)))))))...</td>\n",
       "      <td>EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...</td>\n",
       "      <td>2.485</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.422, 0.5478000000000001, 0.4749000000000000...</td>\n",
       "      <td>[0.4801, 0.7943, 0.42160000000000003, 0.397300...</td>\n",
       "      <td>[0.9822000000000001, 1.272, 0.6940000000000001...</td>\n",
       "      <td>[0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...</td>\n",
       "      <td>[0.9306000000000001, 1.0496, 0.5844, 0.7796000...</td>\n",
       "      <td>[0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...</td>\n",
       "      <td>[0.46040000000000003, 3.6695, 0.78550000000000...</td>\n",
       "      <td>[2.7711, 7.365, 1.6924000000000001, 1.43840000...</td>\n",
       "      <td>[1.073, 2.8604000000000003, 1.9936, 1.0273, 1....</td>\n",
       "      <td>[2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>id_00b436dec</td>\n",
       "      <td>GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...</td>\n",
       "      <td>.....(((((((((((..(((((((((..((((....))))..)))...</td>\n",
       "      <td>EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...</td>\n",
       "      <td>1.727</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.4843, 0.5233, 0.4554, 0.43520000000000003, ...</td>\n",
       "      <td>[0.8719, 1.0307, 0.6649, 0.34500000000000003, ...</td>\n",
       "      <td>[0.7045, 0.7775000000000001, 0.5662, 0.4561, 0...</td>\n",
       "      <td>[0.384, 0.723, 0.4766, 0.30260000000000004, 0....</td>\n",
       "      <td>[0.7429, 0.9137000000000001, 0.480400000000000...</td>\n",
       "      <td>[1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...</td>\n",
       "      <td>[1.6912, 5.2652, 2.3901, 0.45890000000000003, ...</td>\n",
       "      <td>[1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...</td>\n",
       "      <td>[0.49060000000000004, 4.6339, 1.95860000000000...</td>\n",
       "      <td>[1.2852000000000001, 2.5460000000000003, 0.234...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "1      2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "2      5  id_00ab2d761  GGAAAGCGCCGCGGCGGUAGCGGCAGCGAGGAGCGCUACCAAGGCA...   \n",
       "3      6  id_00abef1d7  GGAAAACAAUUGCAUCGUUAGUACGACUCCACAGCGUAAGCUGUGG...   \n",
       "4      7  id_00b436dec  GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  .....((((((.......)))).)).((.....((..((((((......   \n",
       "1  .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "2  .....(.(((((.(((((((((...........)))))))..(((....   \n",
       "3  .........((((((((......((((((((((((....)))))))...   \n",
       "4  .....(((((((((((..(((((((((..((((....))))..)))...   \n",
       "\n",
       "                                 predicted_loop_type  signal_to_noise  \\\n",
       "0  EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "1  EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "2  EEEEESISSSSSISSSSSSSSSHHHHHHHHHHHSSSSSSSMMSSSH...            4.136   \n",
       "3  EEEEEEEEESSSSSSSSIIIIIISSSSSSSSSSSSHHHHSSSSSSS...            2.485   \n",
       "4  EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...            1.727   \n",
       "\n",
       "   SN_filter  seq_length  seq_scored  \\\n",
       "0          1         107          68   \n",
       "1          1         107          68   \n",
       "2          1         107          68   \n",
       "3          1         107          68   \n",
       "4          1         107          68   \n",
       "\n",
       "                                    reactivity_error  \\\n",
       "0  [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...   \n",
       "1  [0.0931, 0.13290000000000002, 0.11280000000000...   \n",
       "2  [0.1942, 0.2041, 0.1626, 0.1213, 0.10590000000...   \n",
       "3  [0.422, 0.5478000000000001, 0.4749000000000000...   \n",
       "4  [0.4843, 0.5233, 0.4554, 0.43520000000000003, ...   \n",
       "\n",
       "                                   deg_error_Mg_pH10  \\\n",
       "0  [0.26130000000000003, 0.38420000000000004, 0.1...   \n",
       "1  [0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...   \n",
       "2  [0.2726, 0.2984, 0.21660000000000001, 0.1637, ...   \n",
       "3  [0.4801, 0.7943, 0.42160000000000003, 0.397300...   \n",
       "4  [0.8719, 1.0307, 0.6649, 0.34500000000000003, ...   \n",
       "\n",
       "                                      deg_error_pH10  \\\n",
       "0  [0.2631, 0.28600000000000003, 0.0964, 0.1574, ...   \n",
       "1  [0.17020000000000002, 0.178, 0.111, 0.091, 0.0...   \n",
       "2  [0.3393, 0.2728, 0.2005, 0.1703, 0.1495, 0.134...   \n",
       "3  [0.9822000000000001, 1.272, 0.6940000000000001...   \n",
       "4  [0.7045, 0.7775000000000001, 0.5662, 0.4561, 0...   \n",
       "\n",
       "                                    deg_error_Mg_50C  \\\n",
       "0  [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...   \n",
       "1  [0.1033, 0.1464, 0.1126, 0.09620000000000001, ...   \n",
       "2  [0.165, 0.20520000000000002, 0.179, 0.1333, 0....   \n",
       "3  [0.5827, 0.7555000000000001, 0.5949, 0.4511, 0...   \n",
       "4  [0.384, 0.723, 0.4766, 0.30260000000000004, 0....   \n",
       "\n",
       "                                       deg_error_50C  \\\n",
       "0  [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "1  [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "2  [0.2864, 0.24710000000000001, 0.2222, 0.1903, ...   \n",
       "3  [0.9306000000000001, 1.0496, 0.5844, 0.7796000...   \n",
       "4  [0.7429, 0.9137000000000001, 0.480400000000000...   \n",
       "\n",
       "                                          reactivity  \\\n",
       "0  [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "1  [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "2  [0.7642, 1.6641, 1.0622, 0.5008, 0.4107, 0.133...   \n",
       "3  [0.895, 2.3377, 2.2305, 2.003, 1.9006, 1.0373,...   \n",
       "4  [1.1576, 1.5137, 1.3382, 1.5622, 1.2121, 0.295...   \n",
       "\n",
       "                                         deg_Mg_pH10  \\\n",
       "0  [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "1  [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "2  [0.9559000000000001, 1.9442, 1.0114, 0.5105000...   \n",
       "3  [0.46040000000000003, 3.6695, 0.78550000000000...   \n",
       "4  [1.6912, 5.2652, 2.3901, 0.45890000000000003, ...   \n",
       "\n",
       "                                            deg_pH10  \\\n",
       "0  [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "1  [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "2  [1.9554, 2.1298, 1.0403, 0.609, 0.5486, 0.386,...   \n",
       "3  [2.7711, 7.365, 1.6924000000000001, 1.43840000...   \n",
       "4  [1.8641, 2.3767, 1.149, 1.0132, 0.9876, 0.0, 0...   \n",
       "\n",
       "                                          deg_Mg_50C  \\\n",
       "0  [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "1  [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "2  [0.22460000000000002, 1.7281, 1.381, 0.6623, 0...   \n",
       "3  [1.073, 2.8604000000000003, 1.9936, 1.0273, 1....   \n",
       "4  [0.49060000000000004, 4.6339, 1.95860000000000...   \n",
       "\n",
       "                                             deg_50C  \n",
       "0  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...  \n",
       "1  [0.9501000000000001, 1.7974999999999999, 1.499...  \n",
       "2  [0.5882000000000001, 1.1786, 0.9704, 0.6035, 0...  \n",
       "3  [2.0964, 3.3688000000000002, 0.6399, 2.1053, 1...  \n",
       "4  [1.2852000000000001, 2.5460000000000003, 0.234...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3634, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_00073f8be</td>\n",
       "      <td>GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAA...</td>\n",
       "      <td>......((((((((((.(((((.....))))))))((((((((......</td>\n",
       "      <td>EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHH...</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id_000ae4237</td>\n",
       "      <td>GGAAACGGGUUCCGCGGAUUGCUGCUAAUAAGAGUAAUCUCUAAAU...</td>\n",
       "      <td>.....((((..((((((...(((((.....((((....)))).......</td>\n",
       "      <td>EEEEESSSSIISSSSSSIIISSSSSIIIIISSSSHHHHSSSSIIII...</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id_00131c573</td>\n",
       "      <td>GGAAAACAAAACGGCCUGGAAGACGAAGGAAUUCGGCGCGAAGGCC...</td>\n",
       "      <td>...........((.(((.(.(..((..((..((((...))))..))...</td>\n",
       "      <td>EEEEEEEEEEESSISSSISISIISSIISSIISSSSHHHSSSSIISS...</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>id_00181fd34</td>\n",
       "      <td>GGAAAGGAUCUCUAUCGAAGGAUAGAGAUCGCUCGCGACGGCACGA...</td>\n",
       "      <td>......((((((((((....))))))))))((((((..((.(((.....</td>\n",
       "      <td>EEEEEESSSSSSSSSSHHHHSSSSSSSSSSSSSSSSIISSISSSHH...</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>id_0020473f7</td>\n",
       "      <td>GGAAACCCGCCCGCGCCCGCCCGCGCUGCUGCCGUGCCUCCUCUCC...</td>\n",
       "      <td>.....(((((((((((((((((((((((((((((((((((((((((...</td>\n",
       "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS...</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_00073f8be  GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAA...   \n",
       "1      1  id_000ae4237  GGAAACGGGUUCCGCGGAUUGCUGCUAAUAAGAGUAAUCUCUAAAU...   \n",
       "2      2  id_00131c573  GGAAAACAAAACGGCCUGGAAGACGAAGGAAUUCGGCGCGAAGGCC...   \n",
       "3      3  id_00181fd34  GGAAAGGAUCUCUAUCGAAGGAUAGAGAUCGCUCGCGACGGCACGA...   \n",
       "4      4  id_0020473f7  GGAAACCCGCCCGCGCCCGCCCGCGCUGCUGCCGUGCCUCCUCUCC...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  ......((((((((((.(((((.....))))))))((((((((......   \n",
       "1  .....((((..((((((...(((((.....((((....)))).......   \n",
       "2  ...........((.(((.(.(..((..((..((((...))))..))...   \n",
       "3  ......((((((((((....))))))))))((((((..((.(((.....   \n",
       "4  .....(((((((((((((((((((((((((((((((((((((((((...   \n",
       "\n",
       "                                 predicted_loop_type  seq_length  seq_scored  \n",
       "0  EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHH...         107          68  \n",
       "1  EEEEESSSSIISSSSSSIIISSSSSIIIIISSSSHHHHSSSSIIII...         130          91  \n",
       "2  EEEEEEEEEEESSISSSISISIISSIISSIISSSSHHHSSSSIISS...         107          68  \n",
       "3  EEEEEESSSSSSSSSSHHHHSSSSSSSSSSSSSSSSIISSISSSHH...         107          68  \n",
       "4  EEEEESSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS...         130          91  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457953, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_seqpos</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00073f8be_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_00073f8be_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_00073f8be_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00073f8be_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_00073f8be_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  deg_50C\n",
       "0  id_00073f8be_0         0.0          0.0       0.0         0.0      0.0\n",
       "1  id_00073f8be_1         0.0          0.0       0.0         0.0      0.0\n",
       "2  id_00073f8be_2         0.0          0.0       0.0         0.0      0.0\n",
       "3  id_00073f8be_3         0.0          0.0       0.0         0.0      0.0\n",
       "4  id_00073f8be_4         0.0          0.0       0.0         0.0      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sub_sample.shape)\n",
    "sub_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2096, 107, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = list(sub_sample.columns[1:])\n",
    "print(targets)\n",
    "\n",
    "y_train = []\n",
    "seq_len = train[\"seq_length\"].iloc[0]\n",
    "seq_len_target = train[\"seq_scored\"].iloc[0]\n",
    "ignore = -10000\n",
    "ignore_length = seq_len - seq_len_target\n",
    "for target in targets:\n",
    "    y = np.vstack(train[target])\n",
    "    dummy = np.zeros([y.shape[0], ignore_length]) + ignore\n",
    "    y = np.hstack([y, dummy])\n",
    "    y_train.append(y)\n",
    "y = np.stack(y_train, axis = 2)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fd3479b0db43b0a7647992ab90a1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2096.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2096, 107, 107, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac108b70a384673ae4e570fa82fec9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=629.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(629, 107, 107, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b50f16b2204ba58f06813cfaa92d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3005.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(3005, 130, 130, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_structure_adj(train):\n",
    "    Ss = []\n",
    "    for i in tqdm(range(len(train))):\n",
    "        seq_length = train[\"seq_length\"].iloc[i]\n",
    "        structure = train[\"structure\"].iloc[i]\n",
    "        sequence = train[\"sequence\"].iloc[i]\n",
    "\n",
    "        cue = []\n",
    "        a_structures = {\n",
    "            (\"A\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"C\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"A\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"C\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "        }\n",
    "        a_structure = np.zeros([seq_length, seq_length])\n",
    "        \n",
    "        for i in range(seq_length):\n",
    "            if structure[i] == \"(\":\n",
    "                cue.append(i)\n",
    "            elif structure[i] == \")\":\n",
    "                start = cue.pop()\n",
    "               \n",
    "                a_structures[(sequence[start], sequence[i])][start, i] = 1\n",
    "                a_structures[(sequence[i], sequence[start])][i, start] = 1\n",
    "        \n",
    "        a_strc = np.stack([a for a in a_structures.values()], axis = 2)\n",
    "        a_strc = np.sum(a_strc, axis = 2, keepdims = True)\n",
    "        Ss.append(a_strc)\n",
    "    \n",
    "    Ss = np.array(Ss)\n",
    "    print(Ss.shape)\n",
    "    return Ss\n",
    "\n",
    "    \n",
    "Ss = get_structure_adj(train)\n",
    "Ss_pub = get_structure_adj(test_pub)\n",
    "Ss_pri = get_structure_adj(test_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 107, 107, 3)\n",
      "(629, 107, 107, 3)\n",
      "(3005, 130, 130, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_distance_matrix(As):\n",
    "    idx = np.arange(As.shape[1])\n",
    "    Ds = []\n",
    "    for i in range(len(idx)):\n",
    "        d = np.abs(idx[i] - idx)\n",
    "        Ds.append(d)\n",
    "\n",
    "    Ds = np.array(Ds) + 1\n",
    "    Ds = 1/Ds\n",
    "    Ds = Ds[None, :,:]\n",
    "    Ds = np.repeat(Ds, len(As), axis = 0)\n",
    "    \n",
    "    Dss = []\n",
    "    for i in [1, 2, 4]:\n",
    "        Dss.append(Ds ** i)\n",
    "    Ds = np.stack(Dss, axis = 3)\n",
    "    print(Ds.shape)\n",
    "    return Ds\n",
    "\n",
    "Ds = get_distance_matrix(As)\n",
    "Ds_pub = get_distance_matrix(As_pub)\n",
    "Ds_pri = get_distance_matrix(As_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 107, 107)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "As.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2096, 107, 107, 5), (629, 107, 107, 5), (3005, 130, 130, 5))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "As = np.concatenate([As[:,:,:,None], Ss, Ds], axis = 3).astype(np.float32)\n",
    "As_pub = np.concatenate([As_pub[:,:,:,None], Ss_pub, Ds_pub], axis = 3).astype(np.float32)\n",
    "As_pri = np.concatenate([As_pri[:,:,:,None], Ss_pri, Ds_pri], axis = 3).astype(np.float32)\n",
    "del Ss, Ds, Ss_pub, Ds_pub, Ss_pri, Ds_pri\n",
    "As.shape, As_pub.shape, As_pri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(2096, 107, 39)\n",
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(629, 107, 39)\n",
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(3005, 130, 39)\n"
     ]
    }
   ],
   "source": [
    "def return_ohe(n, i):\n",
    "    tmp = [0] * n\n",
    "    tmp[i] = 1\n",
    "    return tmp\n",
    "\n",
    "def get_input(train):\n",
    "    mapping = {}\n",
    "    vocab = [\"A\", \"G\", \"C\", \"U\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_node = np.stack(train[\"sequence\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    \n",
    "\n",
    "    mapping = {}\n",
    "    vocab = [\"S\", \"M\", \"I\", \"B\", \"H\", \"E\", \"X\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_loop = np.stack(train[\"predicted_loop_type\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    \n",
    "    mapping = {}\n",
    "    vocab = [\".\", \"(\", \")\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_structure = np.stack(train[\"structure\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    \n",
    "    X_node = np.concatenate([X_node, X_loop, X_structure], axis = 2)\n",
    "    \n",
    "    a = np.sum(X_node * (2 ** np.arange(X_node.shape[2])[None, None, :]), axis = 2)\n",
    "    \n",
    "    vocab = sorted(set(a.flatten()))\n",
    "    print(vocab)\n",
    "    ohes = []\n",
    "    for v in vocab:\n",
    "        ohes.append(a == v)\n",
    "    ohes = np.stack(ohes, axis = 2)\n",
    "    X_node = np.concatenate([X_node, ohes], axis = 2).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    print(X_node.shape)\n",
    "    return X_node\n",
    "\n",
    "\n",
    "X_node = get_input(train)\n",
    "X_node_pub = get_input(test_pub)\n",
    "X_node_pri = get_input(test_pri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def mcrmse(t, p, seq_len_target = seq_len_target):\n",
    "    score = np.mean(np.sqrt(np.mean((p - y_va) ** 2, axis = 2))[:, :seq_len_target])\n",
    "    return score\n",
    "\n",
    "def mcrmse_loss(t, y, seq_len_target = seq_len_target):\n",
    "    t = t[:, :seq_len_target]\n",
    "    y = y[:, :seq_len_target]\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.sqrt(tf.reduce_mean((t - y) ** 2, axis = 2)))\n",
    "    return loss\n",
    "\n",
    "def attention(x_inner, x_outer, n_factor, dropout):\n",
    "    x_Q =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_inner)\n",
    "    x_K =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_V =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_KT = L.Permute((2, 1))(x_K)\n",
    "    res = L.Lambda(lambda c: K.batch_dot(c[0], c[1]) / np.sqrt(n_factor))([x_Q, x_KT])\n",
    "#     res = tf.expand_dims(res, axis = 3)\n",
    "#     res = L.Conv2D(16, 3, 1, padding = \"same\", activation = \"relu\")(res)\n",
    "#     res = L.Conv2D(1, 3, 1, padding = \"same\", activation = \"relu\")(res)\n",
    "#     res = tf.squeeze(res, axis = 3)\n",
    "    att = L.Lambda(lambda c: K.softmax(c, axis=-1))(res)\n",
    "    att = L.Lambda(lambda c: K.batch_dot(c[0], c[1]))([att, x_V])\n",
    "    return att\n",
    "\n",
    "\n",
    "def multi_head_attention(x, y, n_factor, n_head, dropout):\n",
    "    if n_head == 1:\n",
    "        att = attention(x, y, n_factor, dropout)\n",
    "    else:\n",
    "        n_factor_head = n_factor // n_head\n",
    "        heads = [attention(x, y, n_factor_head, dropout) for i in range(n_head)]\n",
    "        att = L.Concatenate()(heads)\n",
    "        att = L.Dense(n_factor, \n",
    "                      kernel_initializer='glorot_uniform',\n",
    "                      bias_initializer='glorot_uniform',\n",
    "                     )(att)\n",
    "    x = L.Add()([x, att])\n",
    "    x = L.LayerNormalization()(x)\n",
    "    if dropout > 0:\n",
    "        x = L.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def res(x, unit, kernel = 3, rate = 0.1):\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "    return L.Add()([x, h])\n",
    "\n",
    "\n",
    "def forward(x, unit, kernel = 3, rate = 0.1):\n",
    "#     h = L.Dense(unit, None)(x)\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "#         h = tf.keras.activations.swish(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = res(h, unit, kernel, rate)\n",
    "    return h\n",
    "\n",
    "\n",
    "\n",
    "def adj_attn(x, adj, unit, n = 2, rate = 0.1):\n",
    "    x_a = x\n",
    "    x_as = []\n",
    "    for i in range(n):\n",
    "        x_a = forward(x_a, unit)\n",
    "        x_a = tf.matmul(adj, x_a)\n",
    "        x_as.append(x_a)\n",
    "    if n == 1:\n",
    "        x_a = x_as[0]\n",
    "    else:\n",
    "        x_a = L.Concatenate()(x_as)\n",
    "    x_a = forward(x_a, unit)\n",
    "    return x_a\n",
    "\n",
    "\n",
    "def get_base(config):\n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    adj_learned = L.Dense(1, \"relu\")(adj)\n",
    "    adj_all = L.Concatenate(axis = 3)([adj, adj_learned])\n",
    "        \n",
    "    xs = []\n",
    "    xs.append(node)\n",
    "    x1 = forward(node, 128, kernel = 3, rate = 0.0)\n",
    "    x2 = forward(x1, 64, kernel = 6, rate = 0.0)\n",
    "    x3 = forward(x2, 32, kernel = 15, rate = 0.0)\n",
    "    x4 = forward(x3, 16, kernel = 30, rate = 0.0)\n",
    "    x = L.Concatenate()([x1, x2, x3, x4])\n",
    "    \n",
    "    for unit in [64, 32]:\n",
    "        x_as = []\n",
    "        for i in range(adj_all.shape[3]):\n",
    "            x_a = adj_attn(x, adj_all[:, :, :, i], unit, rate = 0.0)\n",
    "            x_as.append(x_a)\n",
    "        x_c = forward(x, unit, kernel = 30)\n",
    "        \n",
    "        x = L.Concatenate()(x_as + [x_c])\n",
    "        x = forward(x, unit)\n",
    "        x = multi_head_attention(x, x, unit, 4, 0.0)\n",
    "        xs.append(x)\n",
    "        \n",
    "    x = L.Concatenate()(xs)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    return model\n",
    "\n",
    "def get_ae_model(base, config):\n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "\n",
    "    x = base([L.SpatialDropout1D(0.3)(node), adj])\n",
    "    x = forward(x, 64, rate = 0.3)\n",
    "    p = L.Dense(X_node.shape[2], \"sigmoid\")(x)\n",
    "    \n",
    "    loss = - tf.reduce_mean(20 * node * tf.math.log(p + 1e-4) + (1 - node) * tf.math.log(1 - p + 1e-4))\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [loss])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = lambda t, y : y)\n",
    "    return model\n",
    "\n",
    "def get_model(base, config):\n",
    "    node = tf.keras.Input(shape = (None, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (None, None, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    x = base([node, adj])\n",
    "    x = forward(x, 128, rate = 0.4)\n",
    "    x = L.Dense(5, None)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = mcrmse_loss)\n",
    "    return model\n",
    "\n",
    "def get_optimizer():\n",
    "    adam = tf.optimizers.Adam()\n",
    "\n",
    "    return adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ae_epochs = 50\n",
    "ae_epochs_each = 10\n",
    "ae_batch_size = 32\n",
    "\n",
    "epochs_list = [50, 30, 8, 8, 15, 15]\n",
    "batch_size_list = [8, 16, 32, 64, 128, 256]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 0 ------\n",
      "--- train ---\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 16s 244ms/step - loss: 0.9493\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.3419\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.1734\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.1129\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 14s 209ms/step - loss: 0.0851\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0675\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0566\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0496\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0414\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0416\n",
      "--- public ---\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 362ms/step - loss: 0.0341\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0316\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.0302\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.0304\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0321\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0285\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0312\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0261\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0256\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0316\n",
      "--- private ---\n",
      "Epoch 1/10\n",
      "94/94 [==============================] - 27s 286ms/step - loss: 0.0319\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0307\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0232\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0223\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0205\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0180\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0177\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0172\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0156\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0143\n",
      "------ 1 ------\n",
      "--- train ---\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0146\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0244\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0179\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0154\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0128\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0102\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0104\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0101\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0128\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0107\n",
      "--- public ---\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0136\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0135\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0105\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0112\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0112\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0116\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0104\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0088\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0097\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.0100\n",
      "--- private ---\n",
      "Epoch 1/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0122\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0109\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0116\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0096\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0099\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0094\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0091\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0080\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0079\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0086\n",
      "------ 2 ------\n",
      "--- train ---\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0086\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0081\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0079\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0073\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0087\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0073\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0076\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0061\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0052\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 13s 205ms/step - loss: 0.0073\n",
      "--- public ---\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0058\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0078\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0047\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0072\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0056\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0072\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0068\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0043\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0062\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0059\n",
      "--- private ---\n",
      "Epoch 1/10\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0078\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0076\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0065\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0061\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0078\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0091\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0072\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0066\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0105\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0074\n",
      "------ 3 ------\n",
      "--- train ---\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0060\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0063\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0049\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0051\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0068\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0082\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0052\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0077\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0061\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0043\n",
      "--- public ---\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0041\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0040\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0038\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0029\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0040\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 4s 199ms/step - loss: 0.0057\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0037\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0048\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0040\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.0046\n",
      "--- private ---\n",
      "Epoch 1/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0075\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0064\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0084\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0067\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0063\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0049\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0052\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0052\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0045\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0051\n",
      "------ 4 ------\n",
      "--- train ---\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0042\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0036\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0033\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0048\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0034\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 13s 205ms/step - loss: 0.0038\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 13s 205ms/step - loss: 0.0040\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 13s 205ms/step - loss: 0.0037\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 0.0039\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0048\n",
      "--- public ---\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0044\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0062\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0061\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0048\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0045\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 0.0043\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0044\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0039\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0034\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.0041\n",
      "--- private ---\n",
      "Epoch 1/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0057\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0053\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0050\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0044\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0040\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0074\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0062\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 23s 246ms/step - loss: 0.0050\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0041\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 23s 245ms/step - loss: 0.0041\n",
      "****** save ae model ******\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "\n",
    "if ae_epochs > 0:\n",
    "    base = get_base(config)\n",
    "    ae_model = get_ae_model(base, config)\n",
    "    \n",
    "    for i in range(ae_epochs//ae_epochs_each):\n",
    "        print(f\"------ {i} ------\")\n",
    "        print(\"--- train ---\")\n",
    "        ae_model.fit([X_node, As], [X_node[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        print(\"--- public ---\")\n",
    "        ae_model.fit([X_node_pub, As_pub], [X_node_pub[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        print(\"--- private ---\")\n",
    "        ae_model.fit([X_node_pri, As_pri], [X_node_pri[:,0]],\n",
    "                  epochs = ae_epochs_each,\n",
    "                  batch_size = ae_batch_size)\n",
    "        gc.collect()\n",
    "    print(\"****** save ae model ******\")\n",
    "    base.save_weights(\"./base_ae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ fold 0 start -----\n",
      "------ fold 0 start -----\n",
      "------ fold 0 start -----\n",
      "****** load ae model ******\n",
      "epochs : 50, batch_size : 8\n",
      "Epoch 1/50\n",
      "210/210 [==============================] - 22s 104ms/step - loss: 0.4800\n",
      "Epoch 2/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2551\n",
      "Epoch 3/50\n",
      "210/210 [==============================] - 27s 127ms/step - loss: 0.2300 - val_loss: 0.2116\n",
      "Epoch 4/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2180\n",
      "Epoch 5/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2082\n",
      "Epoch 6/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.2024 - val_loss: 0.1939\n",
      "Epoch 7/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1976\n",
      "Epoch 8/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1932\n",
      "Epoch 9/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1903 - val_loss: 0.1840\n",
      "Epoch 10/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1866\n",
      "Epoch 11/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1832\n",
      "Epoch 12/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1805 - val_loss: 0.1778\n",
      "Epoch 13/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1785\n",
      "Epoch 14/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1769\n",
      "Epoch 15/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1749 - val_loss: 0.1750\n",
      "Epoch 16/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1731\n",
      "Epoch 17/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1717\n",
      "Epoch 18/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1703 - val_loss: 0.1730\n",
      "Epoch 19/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1696\n",
      "Epoch 20/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1679\n",
      "Epoch 21/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1663 - val_loss: 0.1731\n",
      "Epoch 22/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1659\n",
      "Epoch 23/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1646\n",
      "Epoch 24/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1632 - val_loss: 0.1705\n",
      "Epoch 25/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1626\n",
      "Epoch 26/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1615\n",
      "Epoch 27/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1614 - val_loss: 0.1683\n",
      "Epoch 28/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1598\n",
      "Epoch 29/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1589\n",
      "Epoch 30/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1581 - val_loss: 0.1683\n",
      "Epoch 31/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1573\n",
      "Epoch 32/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1565\n",
      "Epoch 33/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1559 - val_loss: 0.1671\n",
      "Epoch 34/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1549\n",
      "Epoch 35/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1541\n",
      "Epoch 36/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1536 - val_loss: 0.1682\n",
      "Epoch 37/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1530\n",
      "Epoch 38/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1522\n",
      "Epoch 39/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1512 - val_loss: 0.1655\n",
      "Epoch 40/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1512\n",
      "Epoch 41/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1508\n",
      "Epoch 42/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1499 - val_loss: 0.1667\n",
      "Epoch 43/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1495\n",
      "Epoch 44/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1489\n",
      "Epoch 45/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1482 - val_loss: 0.1645\n",
      "Epoch 46/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1468\n",
      "Epoch 47/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1472\n",
      "Epoch 48/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1460 - val_loss: 0.1646\n",
      "Epoch 49/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1461\n",
      "Epoch 50/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1454\n",
      "epochs : 30, batch_size : 16\n",
      "Epoch 1/30\n",
      "105/105 [==============================] - 17s 159ms/step - loss: 0.1415\n",
      "Epoch 2/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1402\n",
      "Epoch 3/30\n",
      "105/105 [==============================] - 15s 144ms/step - loss: 0.1395 - val_loss: 0.1629\n",
      "Epoch 4/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1392\n",
      "Epoch 5/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1390\n",
      "Epoch 6/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1390 - val_loss: 0.1633\n",
      "Epoch 7/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1383\n",
      "Epoch 8/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1382\n",
      "Epoch 9/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1376 - val_loss: 0.1634\n",
      "Epoch 10/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1378\n",
      "Epoch 11/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1372\n",
      "Epoch 12/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1373 - val_loss: 0.1629\n",
      "Epoch 13/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1368\n",
      "Epoch 14/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1370\n",
      "Epoch 15/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1365 - val_loss: 0.1630\n",
      "Epoch 16/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1362\n",
      "Epoch 17/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1359\n",
      "Epoch 18/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1355 - val_loss: 0.1628\n",
      "Epoch 19/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1357\n",
      "Epoch 20/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1350\n",
      "Epoch 21/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1348 - val_loss: 0.1638\n",
      "Epoch 22/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1350\n",
      "Epoch 23/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1346\n",
      "Epoch 24/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1340 - val_loss: 0.1640\n",
      "Epoch 25/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1335\n",
      "Epoch 26/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1331\n",
      "Epoch 27/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1332 - val_loss: 0.1633\n",
      "Epoch 28/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1333\n",
      "Epoch 29/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1328\n",
      "Epoch 30/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1324 - val_loss: 0.1637\n",
      "epochs : 8, batch_size : 32\n",
      "Epoch 1/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1302\n",
      "Epoch 2/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1290\n",
      "Epoch 3/8\n",
      "53/53 [==============================] - 12s 227ms/step - loss: 0.1286 - val_loss: 0.1621\n",
      "Epoch 4/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1283\n",
      "Epoch 5/8\n",
      "53/53 [==============================] - 11s 206ms/step - loss: 0.1283\n",
      "Epoch 6/8\n",
      "53/53 [==============================] - 12s 224ms/step - loss: 0.1281 - val_loss: 0.1622\n",
      "Epoch 7/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1281\n",
      "Epoch 8/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1276\n",
      "epochs : 8, batch_size : 64\n",
      "Epoch 1/8\n",
      "27/27 [==============================] - 9s 333ms/step - loss: 0.1266\n",
      "Epoch 2/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1260\n",
      "Epoch 3/8\n",
      "27/27 [==============================] - 11s 425ms/step - loss: 0.1259 - val_loss: 0.1623\n",
      "Epoch 4/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1256\n",
      "Epoch 5/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1253\n",
      "Epoch 6/8\n",
      "27/27 [==============================] - 10s 369ms/step - loss: 0.1252 - val_loss: 0.1620\n",
      "Epoch 7/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1252\n",
      "Epoch 8/8\n",
      "27/27 [==============================] - 9s 335ms/step - loss: 0.1250\n",
      "epochs : 15, batch_size : 128\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 8s 549ms/step - loss: 0.1246\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1244\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 9s 625ms/step - loss: 0.1246 - val_loss: 0.1622\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1247\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1242\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 9s 620ms/step - loss: 0.1240 - val_loss: 0.1625\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1239\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1242\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1239 - val_loss: 0.1622\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1239\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1236\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 9s 618ms/step - loss: 0.1237 - val_loss: 0.1625\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1236\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1235\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - 9s 615ms/step - loss: 0.1237 - val_loss: 0.1620\n",
      "epochs : 15, batch_size : 256\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.1234\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.1233\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.1230 - val_loss: 0.1622\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 7s 991ms/step - loss: 0.1229\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.1227\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1227 - val_loss: 0.1624\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.1225\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.1225\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1224 - val_loss: 0.1624\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.1221\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.1221\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1220 - val_loss: 0.1622\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.1220\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.1218\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1219 - val_loss: 0.1623\n",
      "fold 0: mcrmse 0.16232385027155818\n",
      "------ fold 1 start -----\n",
      "------ fold 1 start -----\n",
      "------ fold 1 start -----\n",
      "****** load ae model ******\n",
      "epochs : 50, batch_size : 8\n",
      "Epoch 1/50\n",
      "210/210 [==============================] - 22s 105ms/step - loss: 0.4958\n",
      "Epoch 2/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2570\n",
      "Epoch 3/50\n",
      "210/210 [==============================] - 28s 132ms/step - loss: 0.2306 - val_loss: 0.2043\n",
      "Epoch 4/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2173\n",
      "Epoch 5/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2093\n",
      "Epoch 6/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.2019 - val_loss: 0.1885\n",
      "Epoch 7/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1981\n",
      "Epoch 8/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1947\n",
      "Epoch 9/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1902 - val_loss: 0.1818\n",
      "Epoch 10/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1874\n",
      "Epoch 11/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1852\n",
      "Epoch 12/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1818 - val_loss: 0.1751\n",
      "Epoch 13/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1794\n",
      "Epoch 14/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1786\n",
      "Epoch 15/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1761 - val_loss: 0.1717\n",
      "Epoch 16/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1744\n",
      "Epoch 17/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1739\n",
      "Epoch 18/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1716 - val_loss: 0.1701\n",
      "Epoch 19/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1706\n",
      "Epoch 20/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1688\n",
      "Epoch 21/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1675 - val_loss: 0.1674\n",
      "Epoch 22/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1672\n",
      "Epoch 23/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1656\n",
      "Epoch 24/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1649 - val_loss: 0.1654\n",
      "Epoch 25/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1638\n",
      "Epoch 26/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1633\n",
      "Epoch 27/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1616 - val_loss: 0.1646\n",
      "Epoch 28/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1609\n",
      "Epoch 29/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1602\n",
      "Epoch 30/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1592 - val_loss: 0.1645\n",
      "Epoch 31/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1591\n",
      "Epoch 32/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1575\n",
      "Epoch 33/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1569 - val_loss: 0.1625\n",
      "Epoch 34/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1563\n",
      "Epoch 35/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1556\n",
      "Epoch 36/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1548 - val_loss: 0.1626\n",
      "Epoch 37/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1547\n",
      "Epoch 38/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1538\n",
      "Epoch 39/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1531 - val_loss: 0.1621\n",
      "Epoch 40/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1525\n",
      "Epoch 41/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1518\n",
      "Epoch 42/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1510 - val_loss: 0.1614\n",
      "Epoch 43/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1505\n",
      "Epoch 44/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1499\n",
      "Epoch 45/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1495 - val_loss: 0.1616\n",
      "Epoch 46/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1492\n",
      "Epoch 47/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1479\n",
      "Epoch 48/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1476 - val_loss: 0.1625\n",
      "Epoch 49/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1478\n",
      "Epoch 50/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1473\n",
      "epochs : 30, batch_size : 16\n",
      "Epoch 1/30\n",
      "105/105 [==============================] - 17s 159ms/step - loss: 0.1430\n",
      "Epoch 2/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1413 - val_loss: 0.1590\n",
      "Epoch 4/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1409\n",
      "Epoch 5/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1407\n",
      "Epoch 6/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1400 - val_loss: 0.1586\n",
      "Epoch 7/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1404\n",
      "Epoch 8/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1398\n",
      "Epoch 9/30\n",
      "105/105 [==============================] - 15s 142ms/step - loss: 0.1397 - val_loss: 0.1590\n",
      "Epoch 10/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1392\n",
      "Epoch 11/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1393\n",
      "Epoch 12/30\n",
      "105/105 [==============================] - 15s 142ms/step - loss: 0.1392 - val_loss: 0.1594\n",
      "Epoch 13/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1388\n",
      "Epoch 14/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1384\n",
      "Epoch 15/30\n",
      "105/105 [==============================] - 15s 142ms/step - loss: 0.1379 - val_loss: 0.1588\n",
      "Epoch 16/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1376\n",
      "Epoch 17/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1374\n",
      "Epoch 18/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1371 - val_loss: 0.1593\n",
      "Epoch 19/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1376\n",
      "Epoch 20/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1365\n",
      "Epoch 21/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1372 - val_loss: 0.1596\n",
      "Epoch 22/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1368\n",
      "Epoch 23/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1363\n",
      "Epoch 24/30\n",
      "105/105 [==============================] - 15s 142ms/step - loss: 0.1357 - val_loss: 0.1590\n",
      "Epoch 25/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1361\n",
      "Epoch 26/30\n",
      "105/105 [==============================] - 14s 130ms/step - loss: 0.1355\n",
      "Epoch 27/30\n",
      "105/105 [==============================] - 15s 142ms/step - loss: 0.1353 - val_loss: 0.1599\n",
      "Epoch 28/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1350\n",
      "Epoch 29/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1343\n",
      "Epoch 30/30\n",
      "105/105 [==============================] - 15s 142ms/step - loss: 0.1346 - val_loss: 0.1607\n",
      "epochs : 8, batch_size : 32\n",
      "Epoch 1/8\n",
      "53/53 [==============================] - 11s 203ms/step - loss: 0.1323\n",
      "Epoch 2/8\n",
      "53/53 [==============================] - 11s 204ms/step - loss: 0.1308\n",
      "Epoch 3/8\n",
      "53/53 [==============================] - 12s 225ms/step - loss: 0.1307 - val_loss: 0.1581\n",
      "Epoch 4/8\n",
      "53/53 [==============================] - 11s 204ms/step - loss: 0.1306\n",
      "Epoch 5/8\n",
      "53/53 [==============================] - 11s 203ms/step - loss: 0.1302\n",
      "Epoch 6/8\n",
      "53/53 [==============================] - 12s 223ms/step - loss: 0.1300 - val_loss: 0.1586\n",
      "Epoch 7/8\n",
      "53/53 [==============================] - 11s 204ms/step - loss: 0.1299\n",
      "Epoch 8/8\n",
      "53/53 [==============================] - 11s 204ms/step - loss: 0.1298\n",
      "epochs : 8, batch_size : 64\n",
      "Epoch 1/8\n",
      "27/27 [==============================] - 9s 334ms/step - loss: 0.1286\n",
      "Epoch 2/8\n",
      "27/27 [==============================] - 9s 334ms/step - loss: 0.1281\n",
      "Epoch 3/8\n",
      "27/27 [==============================] - 11s 420ms/step - loss: 0.1279 - val_loss: 0.1581\n",
      "Epoch 4/8\n",
      "27/27 [==============================] - 9s 334ms/step - loss: 0.1277\n",
      "Epoch 5/8\n",
      "27/27 [==============================] - 9s 334ms/step - loss: 0.1275\n",
      "Epoch 6/8\n",
      "27/27 [==============================] - 10s 367ms/step - loss: 0.1274 - val_loss: 0.1577\n",
      "Epoch 7/8\n",
      "27/27 [==============================] - 9s 334ms/step - loss: 0.1273\n",
      "Epoch 8/8\n",
      "27/27 [==============================] - 9s 334ms/step - loss: 0.1272\n",
      "epochs : 15, batch_size : 128\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1266\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 8s 558ms/step - loss: 0.1267\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 9s 623ms/step - loss: 0.1262 - val_loss: 0.1584\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1262\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1261\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1260 - val_loss: 0.1583\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1260\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 8s 558ms/step - loss: 0.1259\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 9s 616ms/step - loss: 0.1258 - val_loss: 0.1583\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1258\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1258\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1257 - val_loss: 0.1577\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1256\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1258\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - 9s 615ms/step - loss: 0.1256 - val_loss: 0.1586\n",
      "epochs : 15, batch_size : 256\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.1256\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.1253\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.1249 - val_loss: 0.1579\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.1248\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.1248\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1246 - val_loss: 0.1579\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1244\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.1242\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1243 - val_loss: 0.1579\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 7s 991ms/step - loss: 0.1242\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 7s 988ms/step - loss: 0.1241\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1242 - val_loss: 0.1580\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.1240\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.1240\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1240 - val_loss: 0.1581\n",
      "fold 1: mcrmse 0.15810400089962118\n",
      "------ fold 2 start -----\n",
      "------ fold 2 start -----\n",
      "------ fold 2 start -----\n",
      "****** load ae model ******\n",
      "epochs : 50, batch_size : 8\n",
      "Epoch 1/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.4800\n",
      "Epoch 2/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.2637\n",
      "Epoch 3/50\n",
      "210/210 [==============================] - 26s 126ms/step - loss: 0.2348 - val_loss: 0.2154\n",
      "Epoch 4/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.2191\n",
      "Epoch 5/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.2099\n",
      "Epoch 6/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.2034 - val_loss: 0.1955\n",
      "Epoch 7/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1963\n",
      "Epoch 8/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1933\n",
      "Epoch 9/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1888 - val_loss: 0.1896\n",
      "Epoch 10/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1855\n",
      "Epoch 11/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1827\n",
      "Epoch 12/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1808 - val_loss: 0.1871\n",
      "Epoch 13/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1796\n",
      "Epoch 14/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1773\n",
      "Epoch 15/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1748 - val_loss: 0.1778\n",
      "Epoch 16/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1738\n",
      "Epoch 17/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1718\n",
      "Epoch 18/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1711 - val_loss: 0.1767\n",
      "Epoch 19/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1693\n",
      "Epoch 20/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1684\n",
      "Epoch 21/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1667 - val_loss: 0.1748\n",
      "Epoch 22/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1656\n",
      "Epoch 23/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1644\n",
      "Epoch 24/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1634 - val_loss: 0.1733\n",
      "Epoch 25/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1626\n",
      "Epoch 26/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1615\n",
      "Epoch 27/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1606 - val_loss: 0.1740\n",
      "Epoch 28/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1597\n",
      "Epoch 29/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1585\n",
      "Epoch 30/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1584 - val_loss: 0.1716\n",
      "Epoch 31/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1571\n",
      "Epoch 32/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1559\n",
      "Epoch 33/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1558 - val_loss: 0.1688\n",
      "Epoch 34/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1548\n",
      "Epoch 35/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1549\n",
      "Epoch 36/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1535 - val_loss: 0.1699\n",
      "Epoch 37/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1533\n",
      "Epoch 38/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1518\n",
      "Epoch 39/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1513 - val_loss: 0.1681\n",
      "Epoch 40/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1504\n",
      "Epoch 41/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1500\n",
      "Epoch 42/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1496 - val_loss: 0.1700\n",
      "Epoch 43/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1490\n",
      "Epoch 44/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1483\n",
      "Epoch 45/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1482 - val_loss: 0.1705\n",
      "Epoch 46/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1474\n",
      "Epoch 47/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1467\n",
      "Epoch 48/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1466 - val_loss: 0.1679\n",
      "Epoch 49/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1455\n",
      "Epoch 50/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1448\n",
      "epochs : 30, batch_size : 16\n",
      "Epoch 1/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1416\n",
      "Epoch 2/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1400\n",
      "Epoch 3/30\n",
      "105/105 [==============================] - 15s 144ms/step - loss: 0.1395 - val_loss: 0.1656\n",
      "Epoch 4/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1394\n",
      "Epoch 5/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1393\n",
      "Epoch 6/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1388 - val_loss: 0.1651\n",
      "Epoch 7/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1382\n",
      "Epoch 8/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1385\n",
      "Epoch 9/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1381 - val_loss: 0.1650\n",
      "Epoch 10/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1376\n",
      "Epoch 11/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1376\n",
      "Epoch 12/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1371 - val_loss: 0.1662\n",
      "Epoch 13/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1371\n",
      "Epoch 14/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1369\n",
      "Epoch 15/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1366 - val_loss: 0.1652\n",
      "Epoch 16/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1363\n",
      "Epoch 17/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1361\n",
      "Epoch 18/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1358 - val_loss: 0.1650\n",
      "Epoch 19/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1354\n",
      "Epoch 20/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1355\n",
      "Epoch 21/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1349 - val_loss: 0.1661\n",
      "Epoch 22/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1348\n",
      "Epoch 23/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1347\n",
      "Epoch 24/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1343 - val_loss: 0.1669\n",
      "Epoch 25/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1341\n",
      "Epoch 26/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1335\n",
      "Epoch 27/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1336 - val_loss: 0.1668\n",
      "Epoch 28/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1330\n",
      "Epoch 29/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1328\n",
      "Epoch 30/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1329 - val_loss: 0.1659\n",
      "epochs : 8, batch_size : 32\n",
      "Epoch 1/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1305\n",
      "Epoch 2/8\n",
      "53/53 [==============================] - 11s 204ms/step - loss: 0.1290\n",
      "Epoch 3/8\n",
      "53/53 [==============================] - 12s 226ms/step - loss: 0.1288 - val_loss: 0.1644\n",
      "Epoch 4/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1285\n",
      "Epoch 5/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1283\n",
      "Epoch 6/8\n",
      "53/53 [==============================] - 12s 224ms/step - loss: 0.1284 - val_loss: 0.1646\n",
      "Epoch 7/8\n",
      "53/53 [==============================] - 11s 204ms/step - loss: 0.1278\n",
      "Epoch 8/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1280\n",
      "epochs : 8, batch_size : 64\n",
      "Epoch 1/8\n",
      "27/27 [==============================] - 9s 335ms/step - loss: 0.1269\n",
      "Epoch 2/8\n",
      "27/27 [==============================] - 9s 335ms/step - loss: 0.1261\n",
      "Epoch 3/8\n",
      "27/27 [==============================] - 10s 372ms/step - loss: 0.1260 - val_loss: 0.1641\n",
      "Epoch 4/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1258\n",
      "Epoch 5/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1255\n",
      "Epoch 6/8\n",
      "27/27 [==============================] - 10s 368ms/step - loss: 0.1256 - val_loss: 0.1641\n",
      "Epoch 7/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1256\n",
      "Epoch 8/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1253\n",
      "epochs : 15, batch_size : 128\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 8s 558ms/step - loss: 0.1249\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1247\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 9s 620ms/step - loss: 0.1245 - val_loss: 0.1638\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1246\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1245\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 9s 618ms/step - loss: 0.1244 - val_loss: 0.1642\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1243\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1243\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 9s 619ms/step - loss: 0.1242 - val_loss: 0.1641\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1239\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1240\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1240 - val_loss: 0.1643\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1241\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1238\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - 9s 615ms/step - loss: 0.1241 - val_loss: 0.1642\n",
      "epochs : 15, batch_size : 256\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 7s 991ms/step - loss: 0.1241\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.1235\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1233 - val_loss: 0.1640\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.1232\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.1230\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1226 - val_loss: 0.1640\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1227\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.1224\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1226 - val_loss: 0.1639\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 7s 996ms/step - loss: 0.1226\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.1225\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1225 - val_loss: 0.1640\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.1224\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1224\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1221 - val_loss: 0.1639\n",
      "fold 2: mcrmse 0.1638799233738299\n",
      "------ fold 3 start -----\n",
      "------ fold 3 start -----\n",
      "------ fold 3 start -----\n",
      "****** load ae model ******\n",
      "epochs : 50, batch_size : 8\n",
      "Epoch 1/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.4884\n",
      "Epoch 2/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2563\n",
      "Epoch 3/50\n",
      "210/210 [==============================] - 27s 126ms/step - loss: 0.2304 - val_loss: 0.2157\n",
      "Epoch 4/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2169\n",
      "Epoch 5/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2081\n",
      "Epoch 6/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.2020 - val_loss: 0.1967\n",
      "Epoch 7/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1963\n",
      "Epoch 8/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1922\n",
      "Epoch 9/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1904 - val_loss: 0.1845\n",
      "Epoch 10/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1852\n",
      "Epoch 11/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1827\n",
      "Epoch 12/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1808 - val_loss: 0.1787\n",
      "Epoch 13/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1776\n",
      "Epoch 14/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1764\n",
      "Epoch 15/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1747 - val_loss: 0.1793\n",
      "Epoch 16/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1729\n",
      "Epoch 17/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1710\n",
      "Epoch 18/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1697 - val_loss: 0.1748\n",
      "Epoch 19/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1683\n",
      "Epoch 20/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1669\n",
      "Epoch 21/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1661 - val_loss: 0.1736\n",
      "Epoch 22/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1647\n",
      "Epoch 23/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1639\n",
      "Epoch 24/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1631 - val_loss: 0.1729\n",
      "Epoch 25/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1621\n",
      "Epoch 26/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1607\n",
      "Epoch 27/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1603 - val_loss: 0.1712\n",
      "Epoch 28/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1588\n",
      "Epoch 29/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1576\n",
      "Epoch 30/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1572 - val_loss: 0.1714\n",
      "Epoch 31/50\n",
      "210/210 [==============================] - 20s 93ms/step - loss: 0.1567\n",
      "Epoch 32/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1556\n",
      "Epoch 33/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1558 - val_loss: 0.1716\n",
      "Epoch 34/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1546\n",
      "Epoch 35/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1540\n",
      "Epoch 36/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1526 - val_loss: 0.1696\n",
      "Epoch 37/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1516\n",
      "Epoch 38/50\n",
      "210/210 [==============================] - 19s 91ms/step - loss: 0.1518\n",
      "Epoch 39/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1509 - val_loss: 0.1718\n",
      "Epoch 40/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1498\n",
      "Epoch 41/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1493\n",
      "Epoch 42/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1489 - val_loss: 0.1683\n",
      "Epoch 43/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1482\n",
      "Epoch 44/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1482\n",
      "Epoch 45/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1467 - val_loss: 0.1689\n",
      "Epoch 46/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1472\n",
      "Epoch 47/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1461\n",
      "Epoch 48/50\n",
      "210/210 [==============================] - 21s 100ms/step - loss: 0.1456 - val_loss: 0.1675\n",
      "Epoch 49/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1447\n",
      "Epoch 50/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1444\n",
      "epochs : 30, batch_size : 16\n",
      "Epoch 1/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1411\n",
      "Epoch 2/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1394\n",
      "Epoch 3/30\n",
      "105/105 [==============================] - 15s 144ms/step - loss: 0.1389 - val_loss: 0.1667\n",
      "Epoch 4/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1387\n",
      "Epoch 5/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1382\n",
      "Epoch 6/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1381 - val_loss: 0.1658\n",
      "Epoch 7/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1378\n",
      "Epoch 8/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1376\n",
      "Epoch 9/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1373 - val_loss: 0.1664\n",
      "Epoch 10/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1373\n",
      "Epoch 11/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1369\n",
      "Epoch 12/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1364 - val_loss: 0.1669\n",
      "Epoch 13/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1361\n",
      "Epoch 14/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1360\n",
      "Epoch 15/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1360 - val_loss: 0.1667\n",
      "Epoch 16/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1354\n",
      "Epoch 17/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1353\n",
      "Epoch 18/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1349 - val_loss: 0.1663\n",
      "Epoch 19/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1348\n",
      "Epoch 20/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1344\n",
      "Epoch 21/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1346 - val_loss: 0.1667\n",
      "Epoch 22/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1340\n",
      "Epoch 23/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1335\n",
      "Epoch 24/30\n",
      "105/105 [==============================] - 15s 144ms/step - loss: 0.1339 - val_loss: 0.1670\n",
      "Epoch 25/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1336\n",
      "Epoch 26/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1332\n",
      "Epoch 27/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1331 - val_loss: 0.1661\n",
      "Epoch 28/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1325\n",
      "Epoch 29/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1324\n",
      "Epoch 30/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1318 - val_loss: 0.1664\n",
      "epochs : 8, batch_size : 32\n",
      "Epoch 1/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1295\n",
      "Epoch 2/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1286\n",
      "Epoch 3/8\n",
      "53/53 [==============================] - 12s 226ms/step - loss: 0.1282 - val_loss: 0.1654\n",
      "Epoch 4/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1278\n",
      "Epoch 5/8\n",
      "53/53 [==============================] - 11s 204ms/step - loss: 0.1278\n",
      "Epoch 6/8\n",
      "53/53 [==============================] - 12s 224ms/step - loss: 0.1277 - val_loss: 0.1658\n",
      "Epoch 7/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1273\n",
      "Epoch 8/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1274\n",
      "epochs : 8, batch_size : 64\n",
      "Epoch 1/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1263\n",
      "Epoch 2/8\n",
      "27/27 [==============================] - 9s 335ms/step - loss: 0.1256\n",
      "Epoch 3/8\n",
      "27/27 [==============================] - 10s 372ms/step - loss: 0.1252 - val_loss: 0.1652\n",
      "Epoch 4/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1250\n",
      "Epoch 5/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1250\n",
      "Epoch 6/8\n",
      "27/27 [==============================] - 10s 368ms/step - loss: 0.1247 - val_loss: 0.1655\n",
      "Epoch 7/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1248\n",
      "Epoch 8/8\n",
      "27/27 [==============================] - 9s 335ms/step - loss: 0.1246\n",
      "epochs : 15, batch_size : 128\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1241\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1240\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 9s 626ms/step - loss: 0.1238 - val_loss: 0.1654\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1236\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1236\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 9s 619ms/step - loss: 0.1235 - val_loss: 0.1653\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1235\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1233\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1234 - val_loss: 0.1654\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1234\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 8s 559ms/step - loss: 0.1233\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 9s 618ms/step - loss: 0.1232 - val_loss: 0.1657\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1234\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1232\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1231 - val_loss: 0.1656\n",
      "epochs : 15, batch_size : 256\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.1231\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 7s 991ms/step - loss: 0.1228\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1224 - val_loss: 0.1656\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1222\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.1220\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1220 - val_loss: 0.1655\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1219\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.1218\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1215 - val_loss: 0.1655\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1216\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.1217\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1216 - val_loss: 0.1655\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1215\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 7s 991ms/step - loss: 0.1214\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1215 - val_loss: 0.1655\n",
      "fold 3: mcrmse 0.16551536349430412\n",
      "------ fold 4 start -----\n",
      "------ fold 4 start -----\n",
      "------ fold 4 start -----\n",
      "****** load ae model ******\n",
      "epochs : 50, batch_size : 8\n",
      "Epoch 1/50\n",
      "210/210 [==============================] - 19s 93ms/step - loss: 0.5267\n",
      "Epoch 2/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2591\n",
      "Epoch 3/50\n",
      "210/210 [==============================] - 28s 135ms/step - loss: 0.2328 - val_loss: 0.2114\n",
      "Epoch 4/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2199\n",
      "Epoch 5/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.2110\n",
      "Epoch 6/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.2032 - val_loss: 0.1909\n",
      "Epoch 7/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1991\n",
      "Epoch 8/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1947\n",
      "Epoch 9/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1922 - val_loss: 0.1814\n",
      "Epoch 10/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1880\n",
      "Epoch 11/50\n",
      "210/210 [==============================] - 19s 93ms/step - loss: 0.1845\n",
      "Epoch 12/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1825 - val_loss: 0.1772\n",
      "Epoch 13/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1805\n",
      "Epoch 14/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1787\n",
      "Epoch 15/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1766 - val_loss: 0.1731\n",
      "Epoch 16/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1751\n",
      "Epoch 17/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1732\n",
      "Epoch 18/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1715 - val_loss: 0.1706\n",
      "Epoch 19/50\n",
      "210/210 [==============================] - 19s 93ms/step - loss: 0.1697\n",
      "Epoch 20/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1693\n",
      "Epoch 21/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1676 - val_loss: 0.1684\n",
      "Epoch 22/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1664\n",
      "Epoch 23/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1648\n",
      "Epoch 24/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1644 - val_loss: 0.1670\n",
      "Epoch 25/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1635\n",
      "Epoch 26/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1614\n",
      "Epoch 27/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1611 - val_loss: 0.1663\n",
      "Epoch 28/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1605\n",
      "Epoch 29/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1593\n",
      "Epoch 30/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1581 - val_loss: 0.1660\n",
      "Epoch 31/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1575\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1562\n",
      "Epoch 33/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1562 - val_loss: 0.1643\n",
      "Epoch 34/50\n",
      "210/210 [==============================] - 19s 93ms/step - loss: 0.1551\n",
      "Epoch 35/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1542\n",
      "Epoch 36/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1535 - val_loss: 0.1656\n",
      "Epoch 37/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1527\n",
      "Epoch 38/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1526\n",
      "Epoch 39/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1510 - val_loss: 0.1649\n",
      "Epoch 40/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1515\n",
      "Epoch 41/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1504\n",
      "Epoch 42/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1501 - val_loss: 0.1660\n",
      "Epoch 43/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1496\n",
      "Epoch 44/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1485\n",
      "Epoch 45/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1487 - val_loss: 0.1624\n",
      "Epoch 46/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1469\n",
      "Epoch 47/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1470\n",
      "Epoch 48/50\n",
      "210/210 [==============================] - 21s 101ms/step - loss: 0.1466 - val_loss: 0.1638\n",
      "Epoch 49/50\n",
      "210/210 [==============================] - 19s 92ms/step - loss: 0.1460\n",
      "Epoch 50/50\n",
      "210/210 [==============================] - 19s 93ms/step - loss: 0.1452\n",
      "epochs : 30, batch_size : 16\n",
      "Epoch 1/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1416\n",
      "Epoch 2/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1395\n",
      "Epoch 3/30\n",
      "105/105 [==============================] - 15s 145ms/step - loss: 0.1393 - val_loss: 0.1604\n",
      "Epoch 4/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1392\n",
      "Epoch 5/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1391\n",
      "Epoch 6/30\n",
      "105/105 [==============================] - 15s 144ms/step - loss: 0.1388 - val_loss: 0.1611\n",
      "Epoch 7/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1382\n",
      "Epoch 8/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1382\n",
      "Epoch 9/30\n",
      "105/105 [==============================] - 15s 144ms/step - loss: 0.1380 - val_loss: 0.1610\n",
      "Epoch 10/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1377\n",
      "Epoch 11/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1371\n",
      "Epoch 12/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1370 - val_loss: 0.1610\n",
      "Epoch 13/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1372\n",
      "Epoch 14/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1369\n",
      "Epoch 15/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1368 - val_loss: 0.1621\n",
      "Epoch 16/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1365\n",
      "Epoch 17/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1358\n",
      "Epoch 18/30\n",
      "105/105 [==============================] - 15s 144ms/step - loss: 0.1359 - val_loss: 0.1613\n",
      "Epoch 19/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1354\n",
      "Epoch 20/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1350\n",
      "Epoch 21/30\n",
      "105/105 [==============================] - 15s 145ms/step - loss: 0.1349 - val_loss: 0.1615\n",
      "Epoch 22/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1344\n",
      "Epoch 23/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1341\n",
      "Epoch 24/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1342 - val_loss: 0.1625\n",
      "Epoch 25/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1342\n",
      "Epoch 26/30\n",
      "105/105 [==============================] - 14s 132ms/step - loss: 0.1340\n",
      "Epoch 27/30\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 0.1333 - val_loss: 0.1618\n",
      "Epoch 28/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1332\n",
      "Epoch 29/30\n",
      "105/105 [==============================] - 14s 131ms/step - loss: 0.1328\n",
      "Epoch 30/30\n",
      "105/105 [==============================] - 15s 144ms/step - loss: 0.1326 - val_loss: 0.1617\n",
      "epochs : 8, batch_size : 32\n",
      "Epoch 1/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1304\n",
      "Epoch 2/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1289\n",
      "Epoch 3/8\n",
      "53/53 [==============================] - 12s 226ms/step - loss: 0.1287 - val_loss: 0.1606\n",
      "Epoch 4/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1282\n",
      "Epoch 5/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1284\n",
      "Epoch 6/8\n",
      "53/53 [==============================] - 12s 224ms/step - loss: 0.1279 - val_loss: 0.1607\n",
      "Epoch 7/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1278\n",
      "Epoch 8/8\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.1277\n",
      "epochs : 8, batch_size : 64\n",
      "Epoch 1/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1269\n",
      "Epoch 2/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1262\n",
      "Epoch 3/8\n",
      "27/27 [==============================] - 10s 373ms/step - loss: 0.1261 - val_loss: 0.1602\n",
      "Epoch 4/8\n",
      "27/27 [==============================] - 9s 337ms/step - loss: 0.1254\n",
      "Epoch 5/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1257\n",
      "Epoch 6/8\n",
      "27/27 [==============================] - 10s 368ms/step - loss: 0.1252 - val_loss: 0.1603\n",
      "Epoch 7/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1254\n",
      "Epoch 8/8\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.1252\n",
      "epochs : 15, batch_size : 128\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1250\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1245\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 9s 625ms/step - loss: 0.1243 - val_loss: 0.1605\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 8s 562ms/step - loss: 0.1242\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1241\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 9s 618ms/step - loss: 0.1239 - val_loss: 0.1604\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 8s 562ms/step - loss: 0.1238\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1239\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 9s 619ms/step - loss: 0.1238 - val_loss: 0.1608\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1237\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1237\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 9s 619ms/step - loss: 0.1238 - val_loss: 0.1607\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.1237\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.1236\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - 9s 617ms/step - loss: 0.1236 - val_loss: 0.1604\n",
      "epochs : 15, batch_size : 256\n",
      "Epoch 1/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1236\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.1232\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1230 - val_loss: 0.1604\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.1228\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 7s 991ms/step - loss: 0.1227\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1224 - val_loss: 0.1603\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.1224\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.1221\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1223 - val_loss: 0.1603\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.1223\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.1221\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.1220 - val_loss: 0.1604\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.1220\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.1219\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1220 - val_loss: 0.1603\n",
      "fold 4: mcrmse 0.16027487640676225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(5, shuffle = True, random_state = 42)\n",
    "\n",
    "scores = []\n",
    "preds = np.zeros([len(X_node), X_node.shape[1], 5])\n",
    "for i, (tr_idx, va_idx) in enumerate(kfold.split(X_node, As)):\n",
    "    \n",
    "    print(f\"------ fold {i} start -----\")\n",
    "    X_node_tr = X_node[tr_idx]\n",
    "    X_node_va = X_node[va_idx]\n",
    "    As_tr = As[tr_idx]\n",
    "    As_va = As[va_idx]\n",
    "    y_tr = y[tr_idx]\n",
    "    y_va = y[va_idx]\n",
    "    \n",
    "    base = get_base(config)\n",
    "    if ae_epochs > 0:\n",
    "        \n",
    "        base.load_weights(\"./base_ae\")\n",
    "    model = get_model(base, config)\n",
    "    if pretrain_dir is not None:\n",
    "        d = f\"./model{i}\"\n",
    "        print(f\"--- load from {d} ---\")\n",
    "        model.load_weights(d)\n",
    "    for epochs, batch_size in zip(epochs_list, batch_size_list):\n",
    "        print(f\"epochs : {epochs}, batch_size : {batch_size}\")\n",
    "        model.fit([X_node_tr, As_tr], [y_tr],\n",
    "                  validation_data=([X_node_va, As_va], [y_va]),\n",
    "                  epochs = epochs,\n",
    "                  batch_size = batch_size, validation_freq = 3)\n",
    "        \n",
    "    model.save_weights(f\"./model{i}\")\n",
    "    p = model.predict([X_node_va, As_va])\n",
    "    scores.append(mcrmse(y_va, p))\n",
    "    print(f\"fold {i}: mcrmse {scores[-1]}\")\n",
    "    preds[va_idx] = p\n",
    "    \n",
    "    \n",
    "        \n",
    "pd.to_pickle(preds, \"oof.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16232385027155818, 0.15810400089962118, 0.1638799233738299, 0.16551536349430412, 0.16027487640676225]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "p_pub = 0\n",
    "p_pri = 0\n",
    "for i in range(5):\n",
    "    model.load_weights(f\"./model{i}\")\n",
    "    p_pub += model.predict([X_node_pub, As_pub]) / 5\n",
    "    p_pri += model.predict([X_node_pri, As_pri]) / 5\n",
    "    \n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    test_pub[target] = [list(p_pub[k, :, i]) for k in range(p_pub.shape[0])]\n",
    "    test_pri[target] = [list(p_pri[k, :, i]) for k in range(p_pri.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ls = []\n",
    "for df, preds in [(test_pub, p_pub), (test_pri, p_pri)]:\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "\n",
    "        single_df = pd.DataFrame(single_pred, columns=targets)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "        preds_ls.append(single_df)\n",
    "\n",
    "preds_df = pd.concat(preds_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "      <th>id_seqpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reactivity, deg_Mg_pH10, deg_pH10, deg_Mg_50C, deg_50C, id_seqpos]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[(preds_df['reactivity'] < -0.5) | (preds_df['deg_50C'] < -0.5) | (preds_df['deg_Mg_50C'] < -0.5) \n",
    "           | (preds_df['deg_pH10'] < -0.5) | (preds_df['deg_Mg_pH10'] < -0.5)  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "preds_df['deg_Mg_pH10'][(preds_df['deg_Mg_pH10'] < -0.5)]=-0.5\n",
    "preds_df['deg_pH10'][(preds_df['deg_pH10'] < -0.5)]=-0.5\n",
    "preds_df['deg_Mg_50C'][(preds_df['deg_Mg_50C'] < -0.5)]=-0.5\n",
    "preds_df['deg_50C'][(preds_df['deg_50C'] < -0.5)]=-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "      <th>id_seqpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847710</td>\n",
       "      <td>0.603009</td>\n",
       "      <td>1.743468</td>\n",
       "      <td>0.501308</td>\n",
       "      <td>0.740290</td>\n",
       "      <td>id_00073f8be_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.389182</td>\n",
       "      <td>3.087172</td>\n",
       "      <td>4.334582</td>\n",
       "      <td>3.137658</td>\n",
       "      <td>2.724101</td>\n",
       "      <td>id_00073f8be_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.712926</td>\n",
       "      <td>0.598558</td>\n",
       "      <td>0.748595</td>\n",
       "      <td>0.756142</td>\n",
       "      <td>0.683571</td>\n",
       "      <td>id_00073f8be_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.257642</td>\n",
       "      <td>0.893702</td>\n",
       "      <td>1.051911</td>\n",
       "      <td>1.435852</td>\n",
       "      <td>1.599114</td>\n",
       "      <td>id_00073f8be_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.758058</td>\n",
       "      <td>0.502518</td>\n",
       "      <td>0.488114</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>0.811167</td>\n",
       "      <td>id_00073f8be_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C       id_seqpos\n",
       "0    0.847710     0.603009  1.743468    0.501308  0.740290  id_00073f8be_0\n",
       "1    2.389182     3.087172  4.334582    3.137658  2.724101  id_00073f8be_1\n",
       "2    1.712926     0.598558  0.748595    0.756142  0.683571  id_00073f8be_2\n",
       "3    1.257642     0.893702  1.051911    1.435852  1.599114  id_00073f8be_3\n",
       "4    0.758058     0.502518  0.488114    0.806599  0.811167  id_00073f8be_4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.to_csv(\"submission_v3.csv\", index = False)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
